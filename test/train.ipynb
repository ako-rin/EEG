{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58720180",
   "metadata": {},
   "source": [
    "## è½½å…¥åŒ…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b134c237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PGCN_Adapter] Successfully registered PGCN in LibEER.models.Models\n",
      "âœ… Project root: /home/ako/Project/work\n",
      "âœ… LibEER root: /home/ako/Project/work/lib/libeer-ako\n",
      "âœ… Successfully imported Model from EEG.utils.Models\n"
     ]
    }
   ],
   "source": [
    "# æ·»åŠ é¡¹ç›®è·¯å¾„åˆ° sys.path\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# è·å– notebook æ‰€åœ¨ç›®å½•,ç„¶åå‘ä¸Šä¸¤çº§åˆ°è¾¾é¡¹ç›®æ ¹ç›®å½•\n",
    "# /home/ako/Project/work/EEG/test/train.ipynb -> /home/ako/Project/work/\n",
    "notebook_dir = Path(__file__).parent if '__file__' in globals() else Path.cwd()\n",
    "project_root = notebook_dir.parent.parent  # test -> EEG -> work\n",
    "\n",
    "# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•å’Œ libeer-ako åˆ° sys.path\n",
    "libeer_root = project_root / 'lib' / 'libeer-ako'\n",
    "for path in [str(project_root), str(libeer_root)]:\n",
    "    if path not in sys.path:\n",
    "        sys.path.insert(0, path)\n",
    "\n",
    "# ä½¿ç”¨ç»å¯¹å¯¼å…¥\n",
    "from EEG.utils.Models import Model\n",
    "from LibEER.config.setting import seed_sub_dependent_front_back_setting, preset_setting, set_setting_by_args\n",
    "from LibEER.data_utils.load_data import get_data\n",
    "from LibEER.data_utils.split import merge_to_part, index_to_data, get_split_index\n",
    "from LibEER.utils.args import get_args_parser\n",
    "from LibEER.utils.store import make_output_dir\n",
    "from LibEER.utils.utils import state_log, result_log, setup_seed, sub_result_log\n",
    "from LibEER.Trainer.training import train\n",
    "from LibEER.models.DGCNN import NewSparseL2Regularization\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "print(f\"âœ… Project root: {project_root}\")\n",
    "print(f\"âœ… LibEER root: {libeer_root}\")\n",
    "print(f\"âœ… Successfully imported Model from EEG.utils.Models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "898750a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(args):\n",
    "    if args.setting is not None:\n",
    "        setting = preset_setting[args.setting](args)\n",
    "    else:\n",
    "        setting = set_setting_by_args(args)\n",
    "    setup_seed(args.seed)\n",
    "    data, label, channels, feature_dim, num_classes = get_data(setting)\n",
    "    data, label = merge_to_part(data, label, setting)\n",
    "    device = torch.device(args.device)\n",
    "    best_metrics = []\n",
    "    subjects_metrics = [[]for _ in range(len(data))]\n",
    "    for rridx, (data_i, label_i) in enumerate(zip(data, label), 1):\n",
    "        tts = get_split_index(data_i, label_i, setting)\n",
    "        for ridx, (train_indexes, test_indexes, val_indexes) in enumerate(zip(tts['train'], tts['test'], tts['val']), 1):\n",
    "            setup_seed(args.seed)\n",
    "            if val_indexes[0] == -1:\n",
    "                print(f\"train indexes:{train_indexes}, test indexes:{test_indexes}\")\n",
    "            else:\n",
    "                print(f\"train indexes:{train_indexes}, val indexes:{val_indexes}, test indexes:{test_indexes}\")\n",
    "\n",
    "            # split train and test data by specified experiment mode\n",
    "            train_data, train_label, val_data, val_label, test_data, test_label = \\\n",
    "                index_to_data(data_i, label_i, train_indexes, test_indexes, val_indexes, args.keep_dim)\n",
    "            # model to train\n",
    "            if len(val_data) == 0:\n",
    "                val_data = test_data\n",
    "                val_label = test_label\n",
    "\n",
    "            model = Model['DGCNN'](channels, feature_dim, num_classes)\n",
    "            # Train one round using the train one round function defined in the model\n",
    "            dataset_train = torch.utils.data.TensorDataset(torch.Tensor(train_data), torch.Tensor(train_label))\n",
    "            dataset_val = torch.utils.data.TensorDataset(torch.Tensor(val_data), torch.Tensor(val_label))\n",
    "            dataset_test = torch.utils.data.TensorDataset(torch.Tensor(test_data), torch.Tensor(test_label))\n",
    "            optimizer = optim.AdamW(model.parameters(), lr=args.lr, weight_decay=1e-4, eps=1e-4)\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            loss_func = NewSparseL2Regularization(0.01).to(device)\n",
    "            output_dir = make_output_dir(args, \"DGCNN\")\n",
    "            round_metric = train(model=model, dataset_train=dataset_train, dataset_val=dataset_val, dataset_test=dataset_test, device=device,\n",
    "                                 output_dir=output_dir, metrics=args.metrics, metric_choose=args.metric_choose, optimizer=optimizer,\n",
    "                                 batch_size=args.batch_size, epochs=args.epochs, criterion=criterion, loss_func=loss_func, loss_param=model)\n",
    "            best_metrics.append(round_metric)\n",
    "            if setting.experiment_mode == \"subject-dependent\":\n",
    "                subjects_metrics[rridx-1].append(round_metric)\n",
    "    # best metrics: every round metrics dict\n",
    "    # subjects metrics: (subject, sub_round_metric)\n",
    "    if setting.experiment_mode == \"subject-dependent\":\n",
    "        sub_result_log(args, subjects_metrics)\n",
    "    else:\n",
    "        result_log(args, best_metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b7a1d4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: EEG Lib for emotion recognition based on EEG [-batch_size BATCH_SIZE]\n",
      "                                                    [-epochs EPOCHS]\n",
      "                                                    [-device {cuda,cpu}]\n",
      "                                                    [-eval] [-seed SEED]\n",
      "                                                    [-num_workers NUM_WORKERS]\n",
      "                                                    [-loss_func LOSS_FUNC]\n",
      "                                                    [-metrics METRICS [METRICS ...]]\n",
      "                                                    [-metric_choose METRIC_CHOOSE]\n",
      "                                                    [-lr LR]\n",
      "                                                    [-data_dir DATA_DIR]\n",
      "                                                    [-resume]\n",
      "                                                    [-resume_epoch RESUME_EPOCH]\n",
      "                                                    [-checkpoint CHECKPOINT]\n",
      "                                                    [-model MODEL]\n",
      "                                                    [-log_dir LOG_DIR]\n",
      "                                                    [-output_dir OUTPUT_DIR]\n",
      "                                                    [-time TIME]\n",
      "                                                    [-setting {seed_sub_dependent_train_val_test_setting,seediv_sub_dependent_train_val_test_setting,seed_sub_independent_train_val_test_setting,seediv_sub_independent_train_val_test_setting,deap_sub_dependent_train_val_test_setting,hci_sub_dependent_train_val_test_setting,deap_sub_independent_train_val_test_setting,hci_sub_independent_train_val_test_setting,seed_sub_dependent_5fold_setting,seed_sub_dependent_front_back_setting,seed_sub_independent_leave_one_out_setting,seed_cross_session_setting,deap_sub_independent_leave_one_out_setting,deap_sub_dependent_10fold_setting,dreamer_sub_independent_setting,dreamer_sub_dependent_setting,None}]\n",
      "                                                    [-dataset {seed_raw,seediv_raw,deap,deap_raw,hci,dreamer,seed_de,seed_de_lds,seed_psd,seed_psd_lds,seed_dasm,seed_dasm_lds,seed_rasm,seed_rasm_lds,seed_asm,seed_asm_lds,seed_dcau,seed_dcau_lds,seediv_de_lds,seediv_de_movingAve,seediv_psd_movingAve,seediv_psd_lds}]\n",
      "                                                    [-dataset_path DATASET_PATH]\n",
      "                                                    [-low_pass LOW_PASS]\n",
      "                                                    [-high_pass HIGH_PASS]\n",
      "                                                    [-time_window TIME_WINDOW]\n",
      "                                                    [-overlap OVERLAP]\n",
      "                                                    [-sample_length SAMPLE_LENGTH]\n",
      "                                                    [-stride STRIDE]\n",
      "                                                    [-feature_type FEATURE_TYPE]\n",
      "                                                    [-eog_clean] [-only_seg]\n",
      "                                                    [-save_data]\n",
      "                                                    [-normalize NORMALIZE]\n",
      "                                                    [-cross_trail CROSS_TRAIL]\n",
      "                                                    [-experiment_mode EXPERIMENT_MODE]\n",
      "                                                    [-split_type {kfold,leave-one-out,front-back}]\n",
      "                                                    [-fold_num FOLD_NUM]\n",
      "                                                    [-fold_shuffle FOLD_SHUFFLE]\n",
      "                                                    [-front FRONT]\n",
      "                                                    [-sessions SESSIONS [SESSIONS ...]]\n",
      "                                                    [-test_size TEST_SIZE]\n",
      "                                                    [-val_size VAL_SIZE]\n",
      "                                                    [-pr PR [PR ...]]\n",
      "                                                    [-sr SR [SR ...]]\n",
      "                                                    [-bounds BOUNDS [BOUNDS ...]]\n",
      "                                                    [-onehot]\n",
      "                                                    [-label_used LABEL_USED [LABEL_USED ...]]\n",
      "                                                    [-keep_dim]\n",
      "EEG Lib for emotion recognition based on EEG: error: unrecognized arguments: --f=/run/user/1003/jupyter/runtime/kernel-v3a7957caa4a50c7dddfc0e9925db2671561655619.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[31mSystemExit\u001b[39m\u001b[31m:\u001b[39m 2\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    args = get_args_parser()\n",
    "    args = args.parse_args()\n",
    "    # log out train state\n",
    "    state_log(args)\n",
    "    main(args)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9043fc4",
   "metadata": {},
   "source": [
    "## DGCNN Layer [64] å®éªŒ\n",
    "\n",
    "æµ‹è¯• DGCNN åœ¨ SEED æ•°æ®é›†ä¸Šä½¿ç”¨ `layers=[64]` é…ç½®çš„æ•ˆæœ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de980586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… é…ç½®å®Œæˆ:\n",
      "  æ¨¡å‹: DGCNN\n",
      "  æ•°æ®é›†: seed_de_lds\n",
      "  Sessions: [1, 2, 3]\n",
      "  Batch size: 32\n",
      "  Learning rate: 0.0015\n",
      "  Epochs: 80\n",
      "  Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# åˆ›å»ºå‚æ•°é…ç½®\n",
    "class Args:\n",
    "    def __init__(self):\n",
    "        # æ•°æ®é›†é…ç½®\n",
    "        self.dataset = 'seed_de_lds'\n",
    "        self.dataset_path = '../../datasets/SEED'\n",
    "        self.setting = 'seed_sub_dependent_train_val_test_setting'\n",
    "        self.feature_type = 'de_lds'  # âœ… æ·»åŠ \n",
    "        self.time_window = 1           # âœ… æ·»åŠ \n",
    "        \n",
    "        # è®­ç»ƒé…ç½®\n",
    "        self.model = 'DGCNN'\n",
    "        self.batch_size = 32\n",
    "        self.epochs = 80\n",
    "        self.lr = 0.0015\n",
    "        \n",
    "        # è¯„ä¼°æŒ‡æ ‡\n",
    "        self.metrics = ['acc', 'macro-f1']\n",
    "        self.metric_choose = 'macro-f1'\n",
    "        \n",
    "        # å…¶ä»–é…ç½®\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        self.seed = 2024\n",
    "        self.sessions = [1, 2, 3]  # ä½¿ç”¨å…¨éƒ¨ 3 ä¸ª sessions\n",
    "        self.keep_dim = False\n",
    "        self.onehot = True\n",
    "        \n",
    "        # æ ‡ç­¾é…ç½®\n",
    "        self.bounds = None             # âœ… æ·»åŠ \n",
    "        self.label_used = None         # âœ… æ·»åŠ \n",
    "        \n",
    "        # è¾“å‡ºç›®å½•\n",
    "        self.log_dir = './log/'\n",
    "        self.output_dir = './result/'\n",
    "\n",
    "args = Args()\n",
    "print(f\"âœ… é…ç½®å®Œæˆ:\")\n",
    "print(f\"  æ¨¡å‹: {args.model}\")\n",
    "print(f\"  æ•°æ®é›†: {args.dataset}\")\n",
    "print(f\"  ç‰¹å¾ç±»å‹: {args.feature_type}\")\n",
    "print(f\"  Sessions: {args.sessions}\")\n",
    "print(f\"  Batch size: {args.batch_size}\")\n",
    "print(f\"  Learning rate: {args.lr}\")\n",
    "print(f\"  Epochs: {args.epochs}\")\n",
    "print(f\"  Device: {args.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2521c691",
   "metadata": {},
   "source": [
    "### æŸ¥çœ‹ DGCNN ç½‘ç»œç»“æ„\n",
    "\n",
    "åˆ†æ DGCNN çš„æ¯ä¸€å±‚é…ç½®:è¾“å…¥é€šé“ã€è¾“å‡ºé€šé“ã€å‚æ•°é‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67a7486c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "           DGCNN ç½‘ç»œç»“æ„\n",
      "======================================================================\n",
      "\n",
      "â­ å›¾å·ç§¯å±‚é…ç½®:\n",
      "   å±‚æ•°:      1 å±‚\n",
      "   é€šé“æ•°:    [64]\n",
      "   Chebyshev: 2 é˜¶å¤šé¡¹å¼\n",
      "   Dropout:   0.5\n",
      "\n",
      "ğŸ“Š è¾“å…¥è¾“å‡º:\n",
      "   è¾“å…¥: 62 ç”µæ Ã— 5 ç‰¹å¾\n",
      "   è¾“å‡º: 3 ç±»åˆ«\n",
      "\n",
      "ğŸ”„ æ•°æ®æµ:\n",
      "   è¾“å…¥:  (batch, 62, 5)\n",
      "    â†“ GraphConv1: 5â†’64 é€šé“ (640 å‚æ•°)\n",
      "   (batch, 62, 64)\n",
      "    â†“ Flatten\n",
      "   (batch, 3968)\n",
      "    â†“ FC1: 3968â†’256 (1,016,064 å‚æ•°)\n",
      "   (batch, 256)\n",
      "    â†“ FC2: 256â†’3 (771 å‚æ•°)\n",
      "   (batch, 3)\n",
      "\n",
      "ğŸ“Š å‚æ•°ç»Ÿè®¡:\n",
      "   GraphConv:         640\n",
      "   B-ReLU:             64\n",
      "   å…¨è¿æ¥:       1,016,835\n",
      "   é‚»æ¥çŸ©é˜µ:        3,845 (62Ã—62)\n",
      "   ----------------------\n",
      "   æ€»è®¡:         1,021,384 (3.90 MB)\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# åˆ›å»ºä¸€ä¸ª DGCNN æ¨¡å‹å®ä¾‹æ¥æŸ¥çœ‹ç»“æ„\n",
    "# SEED æ•°æ®é›†å‚æ•°\n",
    "num_electrodes = 62  # ç”µææ•°\n",
    "in_channels = 5      # ç‰¹å¾ç»´åº¦ (DE_LDS: delta, theta, alpha, beta, gamma)\n",
    "num_classes = 3      # ç±»åˆ«æ•° (positive, neutral, negative)\n",
    "\n",
    "# åˆ›å»ºæ¨¡å‹ï¼ˆç¦ç”¨ yaml é…ç½®è¾“å‡ºï¼‰\n",
    "import io\n",
    "import sys\n",
    "old_stdout = sys.stdout\n",
    "sys.stdout = io.StringIO()  # ä¸´æ—¶é‡å®šå‘è¾“å‡º\n",
    "dgcnn_model = Model['DGCNN'](num_electrodes, in_channels, num_classes)\n",
    "sys.stdout = old_stdout  # æ¢å¤è¾“å‡º\n",
    "\n",
    "# æ ¸å¿ƒé…ç½®\n",
    "print(\"=\" * 70)\n",
    "print(\"           DGCNN ç½‘ç»œç»“æ„\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nâ­ å›¾å·ç§¯å±‚é…ç½®:\")\n",
    "print(f\"   å±‚æ•°:      {len(dgcnn_model.layers)} å±‚\")\n",
    "print(f\"   é€šé“æ•°:    {dgcnn_model.layers}\")\n",
    "print(f\"   Chebyshev: {dgcnn_model.k} é˜¶å¤šé¡¹å¼\")\n",
    "print(f\"   Dropout:   {dgcnn_model.dropout_rate}\")\n",
    "\n",
    "print(\"\\nğŸ“Š è¾“å…¥è¾“å‡º:\")\n",
    "print(f\"   è¾“å…¥: {num_electrodes} ç”µæ Ã— {in_channels} ç‰¹å¾\")\n",
    "print(f\"   è¾“å‡º: {num_classes} ç±»åˆ«\")\n",
    "\n",
    "# æ•°æ®æµ\n",
    "print(\"\\nğŸ”„ æ•°æ®æµ:\")\n",
    "print(f\"   è¾“å…¥:  (batch, {num_electrodes}, {in_channels})\")\n",
    "\n",
    "for i, layer_ch in enumerate(dgcnn_model.layers):\n",
    "    conv = dgcnn_model.graphConvs[i]\n",
    "    params = conv.weight.numel()\n",
    "    print(f\"    â†“ GraphConv{i+1}: {conv.in_channels}â†’{conv.out_channels} é€šé“ ({params} å‚æ•°)\")\n",
    "\n",
    "last_out = num_electrodes * dgcnn_model.layers[-1]\n",
    "print(f\"   (batch, {num_electrodes}, {dgcnn_model.layers[-1]})\")\n",
    "print(f\"    â†“ Flatten\")\n",
    "print(f\"   (batch, {last_out})\")\n",
    "\n",
    "fc1_params = dgcnn_model.fc.weight.numel() + dgcnn_model.fc.bias.numel()\n",
    "print(f\"    â†“ FC1: {last_out}â†’256 ({fc1_params:,} å‚æ•°)\")\n",
    "print(f\"   (batch, 256)\")\n",
    "\n",
    "fc2_params = dgcnn_model.fc2.weight.numel() + dgcnn_model.fc2.bias.numel()\n",
    "print(f\"    â†“ FC2: 256â†’3 ({fc2_params} å‚æ•°)\")\n",
    "print(f\"   (batch, 3)\")\n",
    "\n",
    "# å‚æ•°ç»Ÿè®¡\n",
    "print(\"\\nğŸ“Š å‚æ•°ç»Ÿè®¡:\")\n",
    "conv_params = sum(c.weight.numel() for c in dgcnn_model.graphConvs)\n",
    "brelu_params = sum(b.bias.numel() for b in dgcnn_model.b_relus)\n",
    "fc_params = fc1_params + fc2_params\n",
    "adj_params = dgcnn_model.adj.numel() + dgcnn_model.adj_bias.numel()\n",
    "total = sum(p.numel() for p in dgcnn_model.parameters())\n",
    "\n",
    "print(f\"   GraphConv:    {conv_params:>8,}\")\n",
    "print(f\"   B-ReLU:       {brelu_params:>8,}\")\n",
    "print(f\"   å…¨è¿æ¥:       {fc_params:>8,}\")\n",
    "print(f\"   é‚»æ¥çŸ©é˜µ:     {adj_params:>8,} (62Ã—62)\")\n",
    "print(f\"   \" + \"-\" * 22)\n",
    "print(f\"   æ€»è®¡:         {total:>8,} ({total*4/1024/1024:.2f} MB)\")\n",
    "\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8133d81b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "å¼€å§‹è®­ç»ƒ DGCNN (layers=[64])\n",
      "============================================================\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Args' object has no attribute 'feature_type'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m60\u001b[39m)\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# è¿è¡Œè®­ç»ƒ\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[43mstate_log\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m main(args)\n\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m + \u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m60\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Project/work/lib/libeer-ako/LibEER/utils/utils.py:13\u001b[39m, in \u001b[36mstate_log\u001b[39m\u001b[34m(args)\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstate_log\u001b[39m(args):\n\u001b[32m     11\u001b[39m     log_dict = {\n\u001b[32m     12\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mdataset\u001b[39m\u001b[33m\"\u001b[39m: args.dataset,\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mfeature type\u001b[39m\u001b[33m\"\u001b[39m: \u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfeature_type\u001b[49m,\n\u001b[32m     14\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m: args.model,\n\u001b[32m     15\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mbatch size\u001b[39m\u001b[33m\"\u001b[39m: args.batch_size,\n\u001b[32m     16\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mepochs\u001b[39m\u001b[33m\"\u001b[39m: args.epochs,\n\u001b[32m     17\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mlearning rate\u001b[39m\u001b[33m\"\u001b[39m: args.lr,\n\u001b[32m     18\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mexperiment mode\u001b[39m\u001b[33m\"\u001b[39m: args.experiment_mode,\n\u001b[32m     19\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33msplit_type\u001b[39m\u001b[33m\"\u001b[39m: args.split_type,\n\u001b[32m     20\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mlog dir\u001b[39m\u001b[33m\"\u001b[39m: args.log_dir,\n\u001b[32m     21\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33moutput dir\u001b[39m\u001b[33m\"\u001b[39m: args.output_dir,\n\u001b[32m     22\u001b[39m     }\n\u001b[32m     23\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33m_\u001b[39m\u001b[33m'\u001b[39m * \u001b[32m43\u001b[39m)\n\u001b[32m     24\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(log_dict.keys(), log_dict.values()):\n",
      "\u001b[31mAttributeError\u001b[39m: 'Args' object has no attribute 'feature_type'"
     ]
    }
   ],
   "source": [
    "# è®­ç»ƒ DGCNN æ¨¡å‹ (layers=[64])\n",
    "# è¿™å°†è‡ªåŠ¨ä½¿ç”¨ DGCNN çš„é»˜è®¤é…ç½®: 62 ç”µæ -> layers=[64]\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"å¼€å§‹è®­ç»ƒ DGCNN (layers=[64])\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# è¿è¡Œè®­ç»ƒ\n",
    "state_log(args)\n",
    "main(args)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"è®­ç»ƒå®Œæˆ!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a100ad",
   "metadata": {},
   "source": [
    "### é¢„æœŸç»“æœ\n",
    "\n",
    "æ ¹æ® DGCNN_train.py ä¸­çš„æ³¨é‡Š:\n",
    "```\n",
    "python DGCNN_train.py -metrics 'acc' 'macro-f1' -metric_choose 'macro-f1' \n",
    "  -setting seed_sub_dependent_train_val_test_setting \n",
    "  -dataset seed_de_lds -batch_size 32 -seed 2024 -epochs 80 -lr 0.0015 -onehot\n",
    "```\n",
    "\n",
    "**é¢„æœŸå‡†ç¡®ç‡**: 0.8255 Â± 0.1561 (acc) / 0.7989 Â± 0.1893 (macro-f1)\n",
    "\n",
    "è¿™ä¸ªé…ç½®åœ¨ SEED æ•°æ®é›†ä¸Š:\n",
    "- ä½¿ç”¨ 62 ä¸ªç”µæ â†’ `layers=[64]` (è‡ªåŠ¨è®¾ç½®)\n",
    "- Subject-dependent æ¨¡å¼\n",
    "- Train/Val/Test ä¸‰åˆ†åˆ’åˆ†\n",
    "- 3 ä¸ª sessions çš„æ•°æ®"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spikingjelly",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
